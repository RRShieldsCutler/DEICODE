{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import \n",
    "import warnings; warnings.simplefilter('ignore') #for PCoA warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "#import data\n",
    "from biom import load_table\n",
    "from gneiss.util import match\n",
    "#plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#MOCK data generation\n",
    "from gneiss import util\n",
    "from gneiss.util import band_diagonal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, poisson, multivariate_normal\n",
    "from skbio.stats.composition import clr\n",
    "#biplots\n",
    "from sklearn.datasets import samples_generator as sg\n",
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "#from sklearn.metrics import consensus_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#completions\n",
    "from DEICODE.untangle import complete_matrix,machine_learning,biplot\n",
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute,IterativeSVD,MICE,MatrixFactorization\n",
    "#transforms \n",
    "from skbio.stats.composition import clr,ilr\n",
    "#PCoA\n",
    "from skbio import DistanceMatrix\n",
    "from skbio.stats.ordination import pcoa\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from skbio.stats import subsample_counts\n",
    "from scipy import stats\n",
    "#splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Intials\n",
    "rand = np.random.RandomState(42)\n",
    "fnts=12\n",
    "# make it look nice\n",
    "sns.set(font=\"monospace\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.display import HTML\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.style.use('seaborn-white')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.style.use('seaborn-paper')\n",
    "HTML(\"\"\"<style>div.cell { /* Tunes the space between cells */margin-top:1em;margin-bottom:1em;}div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 3em;line-height:1.4em;text-align:center;}\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */margin-bottom: -0.4em;}\n",
    "div.text_cell_render { /* Customize text cells */font-family: 'Times New Roman';font-size:2.5em;line-height:1.4em;\n",
    "padding-left:3em;padding-right:3em;}</style>\"\"\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keyboard observation data\n",
    "in_biom='data/benchmarking/keyboard.biom' #import biom file\n",
    "table = load_table(in_biom)\n",
    "read_filter = lambda val, id_, md: sum(val) > 0\n",
    "table.filter(read_filter, axis='sample')\n",
    "table.filter(read_filter, axis='observation')\n",
    "otutabledf=table.to_dataframe()\n",
    "otutabledf=otutabledf.T\n",
    "otutabledf.drop_duplicates(inplace=True)\n",
    "\n",
    "# Get OTU to taxa match\n",
    "taxonomy=table.metadata_to_dataframe('observation')\n",
    "taxonomy.columns=['kingdom', 'phylum', 'class', 'order', \n",
    "                             'family', 'genus', 'species']\n",
    "taxonomy['taxonomy'] = taxonomy[taxonomy.columns].apply(lambda x: ';'.join(x), axis=1)\n",
    "\n",
    "#mapping import \n",
    "map_file='data/benchmarking/keyboard.txt' #import metadata\n",
    "mappingdf= pd.read_table('%s'%map_file, index_col=0,low_memory=False)\n",
    "mappingdf=mappingdf.replace(np.nan,'Unknown', regex=True)\n",
    "mappingdf.index=list(map(str,mappingdf.index))\n",
    "mappingdf=mappingdf.astype(str)\n",
    "mappingdf=mappingdf[~mappingdf.index.duplicated(keep='first')]\n",
    "\n",
    "#match the tables\n",
    "otu_keyboard,mapping_keyboard=match(otutabledf,mappingdf[mappingdf['host_subject_id'].isin(['M2','M3','M9'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import 88 soils observation data\n",
    "in_biom='data/benchmarking/88soils.biom' #import biom file\n",
    "table = load_table(in_biom)\n",
    "#read_filter = lambda val, id_, md: sum(val) > 0\n",
    "read_filter_s = lambda val, id_, md: sum(val) > 500\n",
    "table.filter(read_filter_s, axis='sample')\n",
    "#table.filter(read_filter, axis='observation')\n",
    "otutabledf=table.to_dataframe()\n",
    "otutabledf=otutabledf.T\n",
    "otutabledf.drop_duplicates(inplace=True)\n",
    "\n",
    "# Get OTU to taxa match\n",
    "taxonomy=table.metadata_to_dataframe('observation')\n",
    "taxonomy.columns=['kingdom', 'phylum', 'class', 'order', \n",
    "                             'family', 'genus', 'species']\n",
    "taxonomy['taxonomy'] = taxonomy[taxonomy.columns].apply(lambda x: ';'.join(x), axis=1)\n",
    "\n",
    "#mapping import \n",
    "map_file='data/benchmarking/88soils.txt' #import metadata\n",
    "mappingdf= pd.read_table('%s'%map_file, index_col=0,low_memory=False)\n",
    "mappingdf=mappingdf.replace(np.nan,'Unknown', regex=True)\n",
    "mappingdf.index=list(map(str,mappingdf.index))\n",
    "mappingdf=mappingdf.astype(str)\n",
    "mappingdf=mappingdf[~mappingdf.index.duplicated(keep='first')]\n",
    "\n",
    "#match the tables\n",
    "otu_soils,mapping_soils=match(otutabledf,mappingdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data and metadata into training (75%) and test (25%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Warning: Takes a few min to run \n",
    "\n",
    "# split both datasets (75,25)\n",
    "train_soils, test_soils = train_test_split(otu_soils,test_size=.25)\n",
    "train_keyboard, test_keyboard = train_test_split(otu_keyboard,test_size=.25)\n",
    "\n",
    "#make test and train metadata and match to other df for soils dataset \n",
    "train_soils,mapping_train_soils=match(train_soils,mapping_soils)\n",
    "test_soils,mapping_test_soils=match(test_soils,mapping_soils)\n",
    "\n",
    "#make test and train metadata and match to other df for Keyboard dataset \n",
    "train_keyboard,mapping_train_keyboard=match(train_keyboard,mapping_keyboard)\n",
    "test_keyboard,mapping_test_keyboard=match(test_keyboard,mapping_keyboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test all completion methods on the training datasets \n",
    "\n",
    "## Output is saved as a list where completed_soils contains all soils datasets and completed_keyboard contains all keyboard datasets \n",
    "\n",
    "## The order for each list is :  [Psuedo, OpSpace, KNN, Soft Impute, Iterative SVD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture capt \n",
    "# to prevent a long output from fancy impute \n",
    "\n",
    "#save the output in an ordered list \n",
    "completed_soils=[]\n",
    "completed_keyboard=[]\n",
    "\n",
    "for X_train,la in zip([train_soils,train_keyboard],[completed_soils,completed_keyboard]):\n",
    "        \n",
    "    #psuedo count\n",
    "    la.append(X_train+1)\n",
    "    \n",
    "    # OptSpace\n",
    "    X_filled_opt=complete_matrix(X_train.as_matrix().copy(),rank=3,iteration=20,maxval=10,minval=.01)  \n",
    "    la.append(pd.DataFrame(X_filled_opt,X_train.index,X_train.columns))\n",
    "    \n",
    "    # Make 0 NaN for fancy impute \n",
    "    X_noisefancy=X_train.as_matrix().copy()\n",
    "    X_noisefancy[X_noisefancy==0]=np.nan\n",
    "    \n",
    "    # KNN\n",
    "    X_filled_knn = KNN(k=20,verbose=False,min_value=.01,max_value=10).complete(X_noisefancy)\n",
    "    la.append(pd.DataFrame(X_filled_knn,X_train.index,X_train.columns))\n",
    "    \n",
    "    #soft impute\n",
    "    X_filled_softimpute = SoftImpute(verbose=False,min_value=.01,max_value=10).complete(X_noisefancy)\n",
    "    la.append(pd.DataFrame(X_filled_softimpute,X_train.index,X_train.columns))\n",
    "    \n",
    "    # Iter SVD\n",
    "    X_filled_iter=IterativeSVD(verbose=False,min_value=.01,max_value=1e1).complete(X_noisefancy)\n",
    "    la.append(pd.DataFrame(X_filled_iter,X_train.index,X_train.columns))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Regression analysis and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gneiss.cluster import gradient_linkage\n",
    "from gneiss.regression import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DEICODE_env]",
   "language": "python",
   "name": "conda-env-DEICODE_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
